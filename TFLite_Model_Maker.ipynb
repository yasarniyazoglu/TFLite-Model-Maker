{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Google Drive Bağlantısı**"
      ],
      "metadata": {
        "id": "_qIZ0feCnWal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BKHXpxydIfZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kurulumlar**"
      ],
      "metadata": {
        "id": "sMS0b3HZnd9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhl8lqVamEty"
      },
      "outputs": [],
      "source": [
        "!pip install -q --use-deprecated=legacy-resolver tflite-model-maker\n",
        "!pip install -q pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "### **Veriyi Zipten Çıkarma**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKhU5t1MKhlE"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/d2.zip\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5M8iuydhVae"
      },
      "source": [
        "### **Model Seçimi**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|--------------------|-----------|---------------|----------------------|\n",
        "| EfficientDet-Lite0 | 4.4       | 37            | 25.69%               |\n",
        "| EfficientDet-Lite1 | 5.8       | 49            | 30.55%               |\n",
        "| EfficientDet-Lite2 | 7.2       | 69            | 33.97%               |\n",
        "| EfficientDet-Lite3 | 11.4      | 116           | 37.70%               |\n",
        "| EfficientDet-Lite4 | 19.9      | 260           | 41.96%               |\n"
      ],
      "metadata": {
        "id": "-oLQDUM_jv8z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtdZ-JDwMimd"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('efficientdet_lite2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7wwyI2gLKns"
      },
      "outputs": [],
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc('/content/d2/images/train', '/content/d2/images/train', ['raspberry', 'multimetre', 'salca'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_nGbWyKMANB"
      },
      "outputs": [],
      "source": [
        "validation_data = object_detector.DataLoader.from_pascal_voc('/content/d2/images/test', '/content/d2/images/test', ['raspberry', 'multimetre', 'salca'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "pbtIPQsdJPJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "### **Model Eğitimi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwlYdTcg63xy"
      },
      "outputs": [],
      "source": [
        "model = object_detector.create(train_data, model_spec=spec, epochs=100, batch_size=8, train_whole_model=True, validation_data=validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "### **Modelini Test Etme**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xmnl6Yy7ARn"
      },
      "outputs": [],
      "source": [
        "model.evaluate(validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "### **Export Alma ve TFLite Modelini Test Etme**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm_UULdW7A9T"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='model.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHYDWcljr6jq"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite('/content/model.tflite/model.tflite', validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1egWlephdND"
      },
      "source": [
        "### **Resim Üzerinden Test**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless\n",
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "id": "ouyTwRy2jCQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "model_path = '/content/model.tflite/model.tflite'\n",
        "\n",
        "classes = ['???'] * model.model_spec.config.num_classes\n",
        "label_map = model.model_spec.config.label_map\n",
        "for label_id, label_name in label_map.as_dict().items():\n",
        "  classes[label_id-1] = label_name\n",
        "\n",
        "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
        "\n",
        "def preprocess_image(image_path, input_size):\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  return resized_img, original_image\n",
        "\n",
        "\n",
        "def set_input_tensor(interpreter, image):\n",
        "  tensor_index = interpreter.get_input_details()[0]['index']\n",
        "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
        "  input_tensor[:, :] = image\n",
        "\n",
        "\n",
        "def get_output_tensor(interpreter, index):\n",
        "  output_details = interpreter.get_output_details()[index]\n",
        "  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
        "  return tensor\n",
        "\n",
        "\n",
        "def detect_objects(interpreter, image, threshold):\n",
        "  set_input_tensor(interpreter, image)\n",
        "  interpreter.invoke()\n",
        "\n",
        "  scores = get_output_tensor(interpreter, 0)\n",
        "  boxes = get_output_tensor(interpreter, 1)\n",
        "  count = int(get_output_tensor(interpreter, 2))\n",
        "  classes = get_output_tensor(interpreter, 3)\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results\n",
        "\n",
        "\n",
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path, \n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "\n",
        "    class_id = int(obj['class_id'])\n",
        "\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
        "    cv2.putText(original_image_np, label, (xmin, y),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8"
      ],
      "metadata": {
        "id": "Vrmmtx9dU0J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_IMAGE_URL = \"/content/drive/MyDrive/v4_data/IMG_20210510_085833139.jpg\"\n",
        "DETECTION_THRESHOLD = 0.5 \n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "detection_result_image = run_odt_and_draw_results(\n",
        "    INPUT_IMAGE_URL, \n",
        "    interpreter, \n",
        "    threshold=DETECTION_THRESHOLD\n",
        ")\n",
        "Image.fromarray(detection_result_image)"
      ],
      "metadata": {
        "id": "N-Gq3q9XU2Ec"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TFLite_Model_Maker.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3f06a60cda354d81c2225d2767ee5b44cb4579f2789781878c56ddc9e6e490bb"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('detectron2': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}